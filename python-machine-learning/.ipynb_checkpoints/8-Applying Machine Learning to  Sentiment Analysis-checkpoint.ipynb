{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Applying Machine Learning to Sentiment Analysis\n",
      "\n",
      "\u5728\u5f53\u4eca\u7f51\u7edc\u91cc\uff0c\u4eba\u4eec\u7684\u89c2\u70b9\uff0c\u8c03\u67e5\u4ee5\u53ca\u63a8\u8350\u5df2\u7ecf\u6210\u4e3a\u653f\u6cbb\u548c\u5546\u4e1a\u7684\u8d44\u6e90\u3002\u6b63\u662f\u7531\u4e8e\u5148\u8fdb\u7684\u6280\u672f\uff0c\u8ba9\u6211\u4eec\u53ef\u4ee5\u6536\u96c6\u548c\u5206\u6790\u8fd9\u4e9b\u8d44\u6e90\u3002\u5728\u8fd9\u4e00\u7ae0\u4e2d\uff0c\u6211\u4eec\u5c06\u4f1a\u6d89\u53ca\u5230\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u4e5f\u5373\u662f\u60c5\u611f\u5206\u6790\uff0c\u4ee5\u53ca\u5982\u4f55\u4f7f\u7528\u7b97\u6cd5\u6765\u4ece\u6587\u7ae0\u4e2d\u627e\u51fa\u89c2\u70b9\u3002\n",
      "\n",
      "* \u9884\u5904\u7406\u6587\u672c\u6570\u636e\n",
      "\n",
      "* \u6784\u9020\u6587\u672c\u7279\u5f81\u5411\u91cf\u3001\n",
      "\n",
      "* \u8bad\u7ec3\u4e00\u4e2a\u5206\u7c7b\u60c5\u611f\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\n",
      "\n",
      "* \u901a\u8fc7\u4f7f\u7528out-of-core\u6765\u5904\u7406\u5927\u91cf\u7684\u6587\u672c\u6587\u732e"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Obtaining the IMDb movie review dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\u9996\u5148\u6211\u4eec\u9700\u8981\u5c06\u5355\u72ec\u7684txt\u6587\u4ef6\u5408\u5e76\u6210CSV\u6587\u4ef6\uff0c\u5c06\u5176\u8f6c\u6362\u6210DataFrame\u7ed3\u6784\uff0c\u6211\u4eec\u4f7f\u7528pyPrind\u3002"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyprind"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import os\n",
      "pbar = pyprind.ProgBar(5000)\n",
      "labels = {'pos':1,'neg':0}\n",
      "df = pd.DataFrame()\n",
      "for s in ('test','train'):\n",
      "    for l in ('pos','neg'):\n",
      "        path = 'aclImdb_v1/%s/%s'% (s,l)\n",
      "        for file in os.listdir(path):\n",
      "            with open(os.path.join(path,file),'r') as infile:\n",
      "                txt = infile.read()\n",
      "            df = df.append([[txt,labels[l]]],ignore_index=True)\n",
      "            pbar.update()\n",
      "df.columns=['review','sentiment']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0%                          100%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[                              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#                             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 7.553 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##                            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 7.264 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###                           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 7.002 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[####                          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 6.756 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#####                         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 6.534 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[######                        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 6.336 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#######                       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 6.080 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[########                      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 5.821 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#########                     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 5.565 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##########                    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 5.316 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###########                   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 5.072 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############                  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 4.839 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#############                 ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 4.598 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############                ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 4.343 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###############               ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 4.094 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[################              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 3.837 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#################             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 3.580 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##################            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 3.319 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###################           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 3.053 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[####################          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 2.787 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#####################         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 2.521 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[######################        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 2.249 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#######################       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 1.976 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[########################      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 1.703 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#########################     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 1.424 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##########################    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 1.143 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###########################   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.862 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############################  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.576 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############################# ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.289 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Total time elapsed: 8.730 sec\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.reindex(np.random.permutation(df.index))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('movie_data.csv',index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('movie_data.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>review</th>\n",
        "      <th>sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> OK... so... I really like Kris Kristofferson a...</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> ***SPOILER*** Do not read this, if you think a...</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>3 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 151,
       "text": [
        "                                              review  sentiment\n",
        "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
        "1  OK... so... I really like Kris Kristofferson a...          0\n",
        "2  ***SPOILER*** Do not read this, if you think a...          0\n",
        "\n",
        "[3 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Introducing the bag-of-words model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1.We create a vocabulary of unique tokens\u2014for example, words\u2014from the entire set of documents.\n",
      "\n",
      "2.We construct a feature vector from each document that contains the counts of how often each word occurs in the particular document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count = CountVectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "docs = np.array([\n",
      "                 'The sun is shining',\n",
      "                 'The weather is sweet',\n",
      "                 'The sun is shining and the weather is sweet'\n",
      "                 ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bag = count.fit_transform(docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count.vocabulary_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "{u'and': 0,\n",
        " u'is': 1,\n",
        " u'shining': 2,\n",
        " u'sun': 3,\n",
        " u'sweet': 4,\n",
        " u'the': 5,\n",
        " u'weather': 6}"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bag.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 137,
       "text": [
        "array([[0, 1, 1, 1, 0, 1, 0],\n",
        "       [0, 1, 0, 0, 1, 1, 1],\n",
        "       [1, 2, 1, 1, 1, 2, 1]], dtype=int64)"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = TfidfTransformer()\n",
      "np.set_printoptions(precision=2)\n",
      "tfidf.fit_transform(count.fit_transform(docs)).toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 139,
       "text": [
        "array([[ 0.  ,  0.43,  0.56,  0.56,  0.  ,  0.43,  0.  ],\n",
        "       [ 0.  ,  0.43,  0.  ,  0.  ,  0.56,  0.43,  0.56],\n",
        "       [ 0.4 ,  0.48,  0.31,  0.31,  0.31,  0.48,  0.31]])"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Clean text data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.loc[0,'review'][-50:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 152,
       "text": [
        "'is seven.<br /><br />Title (Brazil): Not Available'"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* \u4f7f\u7528python\u6b63\u5219\u5316\u6765\u53bb\u9664\u4e0d\u5fc5\u8981\u7684html\u6807\u7b7e"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocessor(text):\n",
      "    text = re.sub('<[^>]*>', '', text)\n",
      "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
      "    text = re.sub('[\\W]+', ' ', text.lower()) + ''.join(emoticons).replace('-', '')\n",
      "    return text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preprocessor(df.loc[0,'review'][-50:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "'is seven title brazil not available'"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preprocessor(\"</a>This :) is :( a test :-)!\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "'this is a test :):(:)'"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['review'] = df['review'].apply(preprocessor)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Processing documents into tokens"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenizer(text):\n",
      "    return text.split()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer('runners like running and thus they run')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem.porter import PorterStemmer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "porter = PorterStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenizer_porter(text):\n",
      "    return [porter.stem(word) for word in text.split()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer_porter('runners like running and thus they run')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 163,
       "text": [
        "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Training a logistic regression model for document classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = df.loc[:25000, 'review'].values\n",
      "y_train = df.loc[:25000, 'sentiment'].values\n",
      "X_test = df.loc[25000:, 'review'].values\n",
      "y_test = df.loc[25000:, 'sentiment'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "tfidf = TfidfVectorizer(strip_accents=None,lowercase=False, preprocessor=None)\n",
      "param_grid = [{'vect__ngram_range': [(1,1)],\n",
      "     'vect__stop_words': [stop, None],\n",
      " 'vect__tokenizer': [tokenizer,\n",
      "                               tokenizer_porter],\n",
      " 'clf__penalty': ['l1', 'l2'],\n",
      "         'clf__C': [1.0, 10.0, 100.0]},\n",
      "      {'vect__ngram_range': [(1,1)],\n",
      "           'vect__stop_words': [stop, None],\n",
      "           'vect__tokenizer': [tokenizer,\n",
      "                                   tokenizer_porter],\n",
      "             'vect__use_idf':[False], 'vect__norm':[None],\n",
      "             'clf__penalty': ['l1', 'l2'],\n",
      "            'clf__C': [1.0, 10.0, 100.0]}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we initialized the GridSearchCV object and its parameter grid using the preceding code, we restricted ourselves to a limited number of parameter combinations since the number of feature vectors, as well as the large vocabulary, can make the grid search computationally quite expensive; using a standard Desktop computer, our grid search may take up to 40 minutes to complete."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###\u51c6\u786e\u7387\u5927\u698290%"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stream_docs(path):\n",
      "    with open(path, 'r') as csv:\n",
      "        next(csv) # skip header\n",
      "        for line in csv:\n",
      "             text, label = line[:-3], int(line[-2])\n",
      "             yield text, label  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next(stream_docs(path='movie_data.csv'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 170,
       "text": [
        "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
        " 1)"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_minibatch(doc_stream, size):\n",
      "    docs, y = [], []\n",
      "    try:\n",
      "        for _ in range(size):\n",
      "            text, label = next(doc_stream)\n",
      "            docs.append(text)\n",
      "            y.append(label)\n",
      "    except StopIteration:\n",
      "        return None, None\n",
      "    return docs, y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.linear_model import SGDClassifier"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vect = HashingVectorizer(decode_error='ignore',n_features=2**21,preprocessor=None,tokenizer=tokenizer)\n",
      "clf = SGDClassifier(loss='log', random_state=1, n_iter=1)\n",
      "doc_stream = stream_docs(path='movie_data.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyprind\n",
      "pbar = pyprind.ProgBar(45)\n",
      "classes = np.array([0, 1])\n",
      "for _ in range(45):\n",
      "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
      "    if not X_train:\n",
      "        break\n",
      "    X_train = vect.transform(X_train)\n",
      "    clf.partial_fit(X_train, y_train, classes=classes)\n",
      "    pbar.update()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0%                          100%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[                              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#                             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 14.276 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##                            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 13.090 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###                           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 11.552 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[####                          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 10.417 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#####                         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 9.948 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[######                        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 9.660 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#######                       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 8.976 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[########                      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 8.630 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#########                     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 8.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##########                    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 7.429 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###########                   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 7.133 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############                  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 6.852 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#############                 ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 6.342 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############                ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 6.069 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###############               ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 5.586 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[################              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 5.090 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#################             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 4.854 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##################            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 4.594 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###################           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 4.079 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[####################          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 3.831 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#####################         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 3.339 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[######################        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 2.844 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#######################       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 2.589 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[########################      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 2.327 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#########################     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 1.801 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##########################    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 1.544 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###########################   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 1.026 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############################  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.513 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############################# ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.256 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Total time elapsed: 11.511 sec\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
      "X_test = vect.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.813\n"
       ]
      }
     ],
     "prompt_number": 176
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "np.random.seed(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('movie_data.csv')\n",
      "df.head(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>review</th>\n",
        "      <th>sentiment</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> OK... so... I really like Kris Kristofferson a...</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> ***SPOILER*** Do not read this, if you think a...</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>3 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "                                              review  sentiment\n",
        "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
        "1  OK... so... I really like Kris Kristofferson a...          0\n",
        "2  ***SPOILER*** Do not read this, if you think a...          0\n",
        "\n",
        "[3 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "nltk.download('stopwords')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package 'stopwords' to\n",
        "[nltk_data]     C:\\Users\\hadxu\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package stopwords is already up-to-date!\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem.porter import PorterStemmer\n",
      "porter = PorterStemmer()\n",
      "def tokenizer_porter(text):\n",
      "    return [porter.stem(word) for word in text.split()]\n",
      "from nltk.corpus import stopwords\n",
      "stop = stopwords.words('english')\n",
      "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:] if w not in stop]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "['runner', 'like', 'run', 'run', 'lot']"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.loc[0,'review'][-50:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "'is seven.<br /><br />Title (Brazil): Not Available'"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['review'] = df['review'].apply(preprocessor)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenizer(text):\n",
      "    return text.split()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#\u4e3a\u4e0b\u4e00\u7ae0\u505a\u7684\u51c6\u5907"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import re\n",
      "from nltk.corpus import stopwords\n",
      "stop = stopwords.words('english')\n",
      "def tokenizer(text):\n",
      "    text = re.sub('<[^>]*>', '', text)\n",
      "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text.lower())\n",
      "    text = re.sub('[\\W]+', ' ', text.lower())+ ' '.join(emoticons).replace('-', '')\n",
      "    tokenized = [w for w in text.split() if w not in stop]\n",
      "    return tokenized\n",
      "def stream_docs(path):\n",
      "    with open(path, 'r') as csv:\n",
      "        next(csv) # skip header\n",
      "        for line in csv:\n",
      "             text, label = line[:-3], int(line[-2])\n",
      "             yield text, label               "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next(stream_docs(path='./movie_data.csv'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "('\"In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"\"Murder in Greenwich\"\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available\"',\n",
        " 1)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_minibatch(doc_stream, size):\n",
      "    docs, y = [], []\n",
      "    try:\n",
      "        for _ in range(size):\n",
      "            text, label = next(doc_stream)\n",
      "            docs.append(text)\n",
      "            y.append(label)\n",
      "    except StopIteration:\n",
      "        return None, None\n",
      "    return docs, y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "vect = HashingVectorizer(decode_error='ignore',n_features=2**21,preprocessor=None,tokenizer=tokenizer)\n",
      "clf = SGDClassifier(loss='log', random_state=1, n_iter=1)\n",
      "doc_stream = stream_docs(path='movie_data.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyprind\n",
      "pbar = pyprind.ProgBar(45)\n",
      "classes = np.array([0, 1])\n",
      "for _ in range(45):\n",
      "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
      "    if not X_train:\n",
      "        break\n",
      "    X_train = vect.transform(X_train)\n",
      "    clf.partial_fit(X_train, y_train, classes=classes)\n",
      "    pbar.update()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "0%                          100%\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[                              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#                             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 167.915 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##                            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 160.818 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###                           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 153.624 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[####                          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 145.095 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#####                         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 140.563 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[######                        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 136.460 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#######                       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 129.367 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[########                      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 125.174 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#########                     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 117.364 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##########                    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 109.959 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###########                   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 105.855 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############                  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 101.947 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#############                 ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 94.234 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############                ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 90.403 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###############               ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 82.792 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[################              ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 75.172 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#################             ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 71.334 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##################            ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 67.521 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###################           ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 59.864 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[####################          ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 56.061 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#####################         ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 48.605 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[######################        ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 41.070 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#######################       ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 37.339 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[########################      ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 33.604 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[#########################     ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 26.077 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##########################    ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 22.364 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[###########################   ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 14.899 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############################  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 7.443 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[############################# ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 3.723 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "[##############################]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        " | ETA[sec]: 0.000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Total time elapsed: 167.394 sec\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
      "X_test = vect.transform(X_test)\n",
      "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.868\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = clf.partial_fit(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "import os\n",
      "dest = os.path.join('movieclassifier', 'pkl_objects')\n",
      "if not os.path.exists(dest):\n",
      "    os.makedirs(dest) \n",
      "    pickle.dump(stop,open(os.path.join(dest, 'stopwords.pkl'),'wb'),protocol=2)\n",
      "pickle.dump(clf,open(os.path.join(dest, 'classifier.pkl'), 'wb'),protocol=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##\u603b\u7ed3\n",
      "\u8fd9\u4e00\u7ae0\u6211\u5728\u505a\u4e0b\u9762\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u65f6\u5019\u53c8\u770b\u4e86\u4e00\u904d\uff0c\u7531\u4e8e2.7\u4e0e3.4\u7684\u4e0d\u517c\u5bb9\u9020\u6210\u7684\u3002"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}